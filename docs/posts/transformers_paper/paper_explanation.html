<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Alex Paul Kelly">
<meta name="dcterms.date" content="2024-03-30">

<title>Alex Paul Kelly - Paper reading group - Attention is All You Need</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Alex Paul Kelly</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/resolver101757" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/alex_paul_kelly" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/alexpkelly/" rel="" target=""><i class="bi bi-linkedin" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Paper reading group - Attention is All You Need</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">NLP</div>
                <div class="quarto-category">Attention</div>
                <div class="quarto-category">Transformer</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Alex Paul Kelly </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 30, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#why-transformers" id="toc-why-transformers" class="nav-link" data-scroll-target="#why-transformers">Why transformers</a></li>
  <li><a href="#model-architecture" id="toc-model-architecture" class="nav-link" data-scroll-target="#model-architecture">Model Architecture</a></li>
  <li><a href="#input-encoder-components" id="toc-input-encoder-components" class="nav-link" data-scroll-target="#input-encoder-components">(input) encoder components</a></li>
  <li><a href="#output-decoder" id="toc-output-decoder" class="nav-link" data-scroll-target="#output-decoder">(output) decoder</a></li>
  <li><a href="#further-understanding-of-the-multi-attention-headers" id="toc-further-understanding-of-the-multi-attention-headers" class="nav-link" data-scroll-target="#further-understanding-of-the-multi-attention-headers">Further understanding of the multi-attention headers</a>
  <ul>
  <li><a href="#easy-analogy-for-qkv-mechanism" id="toc-easy-analogy-for-qkv-mechanism" class="nav-link" data-scroll-target="#easy-analogy-for-qkv-mechanism">Easy Analogy for QKV Mechanism</a></li>
  <li><a href="#easy-analogy-for-multiple-heads" id="toc-easy-analogy-for-multiple-heads" class="nav-link" data-scroll-target="#easy-analogy-for-multiple-heads">Easy Analogy for Multiple Heads</a></li>
  </ul></li>
  <li><a href="#futher-studying" id="toc-futher-studying" class="nav-link" data-scroll-target="#futher-studying">Futher studying</a>
  <ul>
  <li><a href="#video-summaries" id="toc-video-summaries" class="nav-link" data-scroll-target="#video-summaries">Video Summaries</a></li>
  <li><a href="#statquest-youtube-videos" id="toc-statquest-youtube-videos" class="nav-link" data-scroll-target="#statquest-youtube-videos">Statquest youtube videos</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Every 2nd Saturday we have a paper reading group where we submit papers we are interested in reading and vote for our favorite paper to read together. This week we discussed the paper “Attention is All You Need” (2017). This paper introduced the Transformer model, which has since become the foundation for many state-of-the-art models such as ChatGPT. This is my take on Transformers, why it is so important and why it’s used so widely. The aim is not to go into extensive details as numerous resources online already exist but to give an intuitive understanding and provide resources I found useful in understanding transformers from different perspectives, e.g.&nbsp;from a visual, maths, code and conceptual. I will assume you have basic understanding of Neural networks, back propagation ect and i will be using the token and words interchangeably, token being part of a word that language models use.</p>
</section>
<section id="why-transformers" class="level1">
<h1>Why transformers</h1>
<p>To understand why Transformers, first, you need to understand what came before. RNNs are sequenced based models and each word or token has to be processed before the next token can be processed. This doesn’t lend itself to utilizing the GPUs as the model is limited by waiting for the previous token. They are deep networks with lots of layers with hidden states that carry information from previously seen inputs. When long sequences are passed this increases the chances of vanishing and exploding gradients which reduces the effectiveness of the network, a flaw in the design. To resolve these issues, LSTMs (long short memory) models is designed with 2 pathways, one for learning the more immediate tokens and another pathway for a longer memory. This has the same sequence issue but has an improvement in longer-range context. However, this still didn’t provide accurate enough predictions of tokens, was still sequential and didn’t use all the resources of the GPUs which means slower training.</p>
<p>Next comes transformers with their paper “attention is all you need”. Transformers are fantastic models that change how the models are organized, they incorporate the idea of attention, hence the paper’s name “attention is all you need”. They use a method called Query, Key and Value vectors (attention headers) to keep multiple perspectives of relationships between tokens (or words) and their meanings. This makes the Transformer model highly parallelizable and efficient, leading to significant improvements in training speed and performance for all types of modalities more notably text as described in the paper. The attention also increases the performance with longer sequences. In summary, this has the following benefits:</p>
<ul>
<li>It does not use recurrence or convolution which are the traditional methods for sequence modeling such as RNNs and LSTMs</li>
<li>Relies entirely on attention mechanisms to draw global dependencies between input and output</li>
<li>Parallelization allows for faster training times and full use of GPU resources</li>
<li>The model is highly modular and can be easily adapted to different tasks by changing the input and output representations</li>
</ul>
</section>
<section id="model-architecture" class="level1">
<h1>Model Architecture</h1>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="transformer.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Transformer Model Architecture</figcaption>
</figure>
</div>
<p>The architecture above is split into 2 ways, the left side is the encoder and the right side is the decoder. A good way to think about good way to think about this is that the encoder is like a meticulous note-taker, capturing all the critical information and its interrelations. The decoder is like a storyteller or translator, using those notes to create a new, coherent narrative or translation that reflects the captured information accurately but in a different form.</p>
</section>
<section id="input-encoder-components" class="level1">
<h1>(input) encoder components</h1>
<ul>
<li>Input Embedding: This can be thought of as a dictionary, each word (or token) is referenced as a single vector. This also captures the semantic information of the words and their relationship to each other. This context information is important for the understanding of the meaning of each word is to each other.<br>
</li>
<li>Positional Encodings: This is used to track the position of the word for the model to understand its relevance due to its position. The words are not inherently processed in order so keeping track of the order is important. This is an important part that allows the model to process in parallel.<br>
</li>
<li>Multi-headed Attention: This is where the magic of the self-attention is performed. Each head will keep track of it’s relationship to other words and its semantic understanding. In the paper, there are 8 heads meaning there are 8 different perspectives for each word (or token) and their relationship to the other words and the great meaning. Each head is different due to the random weights assigned at the start, these weights are then updated during training to hone in on different perspectives that matter the most in reference to the training data.<br>
</li>
<li>The feed forward layer: before the forward feed, the heads are concatenated and sent to the feed foward layer for further transformations to improve the understanding of all the heads and gain a better conceptual understanding to improve the overall accuracy of the model.</li>
<li>Finally, this is then passed to the decoder part of the model to be decoded</li>
</ul>
</section>
<section id="output-decoder" class="level1">
<h1>(output) decoder</h1>
<ul>
<li>Output Embeddings: This is the same as the input embeddings, there is no difference on this layer, only when the embeddings reach the masked layers. They can be thought of as a dictionary, each word (or token) is referenced as a single vector. This also captures the semantic information of the words and their relationship to each other. This context information is important for the understanding of the meaning of each word is to each other.<br>
</li>
<li>Positional Encodings: This is used to track the position of the word for the model to understand its relevance due to its position. The words are not inherently processed in order so keeping track of the order is important. This is an important part that allows the model to process in parallel.<br>
</li>
<li>Masked multi-head attention: Its aim is similar to the multi-headed attention in the encoder but to iteratively learn the relationship and semantic meanings one token at a time to predict the next token. For example, if the sentence to translate is “you are the best” to French, the first token is “you”, then the 2nd word “you are”, 3rd word “you are the” and 4th “you are the best” each time asking “given what you know so far, whats the next token”. This is how the masking process works but this can be done in parallel.</li>
<li>Multi-headed Attention: This again is where this gets really interesting. This layer takes the whole semantic meaning from the encoder of the whole input tokens and also the masked multi-head attention (up to the point it’s at e.g.&nbsp;“you Are”) to predict the next token. It applies several heads to pay attention to different aspects of the information passed.<br>
</li>
<li><ul>
<li>The feed forward layer: before the forward feed, the heads are concatenated and sent to the feed foward layer for further transformations to improve the understanding of all the heads and gain a better conceptual understanding to improve the overall accuracy of the model.</li>
</ul></li>
<li>Linear Layer: The linear layers gain further understanding and produce the logits to pass to the softmax function</li>
<li>Softmax function: The softmax function converts the logits to a probability and the highest probability word is selected.</li>
</ul>
</section>
<section id="further-understanding-of-the-multi-attention-headers" class="level1">
<h1>Further understanding of the multi-attention headers</h1>
<p>Understanding the intuition behind multi-attention headers is quite difficult. I found these analogies helped in understanding and also retaining the purpose. The multi-attention headers are made of Query, Key and Value. Let’s simplify the concept of the QKV mechanism in transformers and the rationale behind using multiple heads with an easy-to-grasp analogies</p>
<section id="easy-analogy-for-qkv-mechanism" class="level2">
<h2 class="anchored" data-anchor-id="easy-analogy-for-qkv-mechanism">Easy Analogy for QKV Mechanism</h2>
<p>Imagine you’re at a large dinner party, trying to follow the conversations around the table:</p>
<p>Query (Q): This is like you trying to understand a comment made by someone. You’re focused on this comment and trying to figure out its context and relevance to the conversation. Key (K): Think of every person at the table as holding a “key” to different pieces of information. Some of what they say will be more relevant to understanding the comment you’re focused on, and some less so. Value (V): The “value” is the actual content or meaning each person (key) can contribute to help you understand the comment in question. After deciding whose input is most relevant, you’ll pay more attention to what those few people are saying. The transformer, like you in this scenario, uses the QKV mechanism to decide which parts of the input (the conversation) to pay attention to when trying to understand each piece (word or comment).</p>
</section>
<section id="easy-analogy-for-multiple-heads" class="level2">
<h2 class="anchored" data-anchor-id="easy-analogy-for-multiple-heads">Easy Analogy for Multiple Heads</h2>
<p>Continuing with the dinner party analogy, imagine now that you’re not just trying to understand the content of the conversation but also the emotional tone, who’s leading the conversation, and how topics are changing over time.</p>
<p>Having multiple heads is like having several versions of you at the party, each with a different focus. One version of you is trying to follow the main topic, another is paying attention to the emotional undercurrents, another is noting how the conversation topics shift, and so on. Each “version” of you can focus on different aspects of the conversation simultaneously, ensuring that you get a fuller understanding of what’s happening at the dinner party than you would if you were just trying to follow the main topic. In essence, the QKV mechanism with multiple heads allows the transformer to “attend” to a complex sequence (like a conversation) from multiple perspectives at once, ensuring it captures the rich, multifaceted nature of the data it’s processing.</p>
</section>
</section>
<section id="futher-studying" class="level1">
<h1>Futher studying</h1>
<p>These are all the links, blogs to help understand transformers better. If you want to dive deeper, understand your own learning style and pick option that suites you:</p>
<p><a href="https://arxiv.org/abs/1706.03762">The paper</a></p>
<p><a href="https://benjaminwarner.dev/2023/07/01/attention-mechanism">A two-part blog post on creating a transformer from scratch in PyTorch - Part 1</a></p>
<p><a href="https://benjaminwarner.dev/2023/07/28/rest-of-the-transformer">A two-part blog post on creating a transformer from scratch in PyTorch - Part 2</a></p>
<p><a href="https://maximilian-weichart.de/posts/rnn-1/">Introduction to RNNs (by our very own)</a></p>
<p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a></p>
<p><a href="https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder">Understanding Encoder and Decoder LLMs</a></p>
<p><a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a></p>
<p><a href="https://jalammar.github.io/illustrated-gpt2/">The Illustrated GPT-2</a></p>
<p><a href="https://www.youtube.com/watch?v=wjZofJX0v4M">Visual video on transformers by 3Blue1Brown</a></p>
<p><a href="https://txt.cohere.com/sentence-word-embeddings/">What are Word and Sentence Embeddings? (5-10 minute read)</a></p>
<section id="video-summaries" class="level2">
<h2 class="anchored" data-anchor-id="video-summaries">Video Summaries</h2>
<p><a href="https://www.youtube.com/watch?v=4Bdc55j80l8">15 min—really fantastic animated summary</a> <a href="https://www.youtube.com/watch?v=-QH8fRhqFHM">30 min–video supplement to The Illustrated Transformer</a> <a href="https://youtu.be/g3sEsBGkLU0?feature=shared">50 min—fantastic code walkthrough of encoder</a> <a href="https://youtu.be/MqDehUoMk-E?feature=shared">40 min—fantastic code walkthrough of decoder</a></p>
</section>
<section id="statquest-youtube-videos" class="level2">
<h2 class="anchored" data-anchor-id="statquest-youtube-videos">Statquest youtube videos</h2>
<p><a href="https://www.youtube.com/watch?v=zxQyTK8quyY&amp;pp=ygUJc3RhdHF1ZXN0">Transformers</a><br> <a href="https://www.youtube.com/watch?v=bQ5BoolX9Ag&amp;t=1936s&amp;pp=ygUJc3RhdHF1ZXN0">Decoders only trasnformers</a><br> <a href="https://www.youtube.com/watch?v=YCzL96nL7j0">LSTMs</a><br> <a href="https://www.youtube.com/watch?v=L8HKweZIOmg">Seq2Seq</a><br> <a href="https://www.youtube.com/watch?v=PSs6nxngL6k">Attention for neural networks</a><br> <a href="https://www.youtube.com/watch?v=e9U0QAFbfLI&amp;t">Cosine similarity</a><br></p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>